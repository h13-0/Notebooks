---
number headings: auto, first-level 2, max 6, 1.1
---
#机器学习 #CV 

## 1 目录

```toc
```

## 2 通俗例子

假设现在我们有如下的字典(dict)：

| 身高(Key) | 平均体重(Value) |
| :-----: | :---------: |
|   160   |     60      |
|   ...   |     ...     |
|   177   |     73      |
|   179   |     78      |
|   ...   |     ...     |
|   191   |     90      |
|   ...   |     ...     |

现在我们要依靠上述表格预测身高为178cm的人的体重，那么我们的第一反应大概率是：
$$Pred(178)=\frac{Weight(177)+Weight(179)}{2}$$
在上述过程中，<font color="#c00000">我们并没有去关注身高为160cm和191cm对应的体重</font>，<span style="background:#fff88f"><font color="#c00000">而仅仅关注了177cm和179cm的</font></span>身高体重数据(因为177和179离178最近)。<span style="background:#fff88f"><font color="#c00000">那么这个过程就可以理解为一个注意力机制</font></span>。当然，下面的[[注意力机制#^dp335f|加权平均法]]也可以理解为一种自注意力机制。

这里先约定三个重要的参数：
- Q：Query，用于预测的输入
- K：Key，
- V：Value，

在上面的体重预测过程中，我们还可以有如下的预测方法(加权平均法)：
$$Pred(x)=\displaystyle \sum^{n}_{i=1}{k_i \times Height_i}, i\in n$$
其中： ^dp335f
- $k_i$ 为权重系数
- $i$ 为数据集索引
替换为Q、K、V的表达式则为：
$$Pred(Q)=\displaystyle \sum^{n}_{i=1}{\alpha (Q, K_i) \times V_i}, i\in n$$
其中：
- $\alpha$ 为评价 $Q$ 和 $K$ 相关性的函数，需要归一化。

## 3 

将上一章节的


转化为线性代数形式则有：






## 4 参考资料


