#计算机组成原理 #应试笔记与八股 

## 目录

```toc
```

## 3.1 存储器概述

按照离CPU的层次分类：
- ![[Pasted image 20250304111239.png]]
0. 寄存器
1. Cache
2. 主存
3. 辅存、外存：磁盘、U盘、磁带、光盘
其中：
1. <font color="#c00000">Cache-主存之间的数据同步是依靠硬件</font><span style="background:#fff88f"><font color="#c00000">自动完成的</font></span>(<font color="#c00000">解决了CPU和主存速度不匹配的问题</font>)
2. 主存-辅存之间的数据置换的方式有：
	1. <font color="#c00000">操作系统的页面置换算法</font>(实现了虚拟存储系统)
	2. 普通文件操作等

按照存储介质进行分类：
1. 半导体存储器
2. 磁性存储器
3. 光存储器

按照存取方式进行分类：
1. 随机存取存储器(RAM、Random Access Memory)：读写任意一个存储单元所需时间都相同，例如内存等。
2. 顺序存取存储器(SAM、Sequential Access Memory)：读写一个存储单元所需时间取决于存储单元所在位置，例如磁带等。
3. 直接存取存储器(DAM、Direct Access Memory)：既有随机存取的特性，也有顺序存取的特性。区域(扇区)间随机读取，区域(扇区)内顺序读取，例如磁盘等。
4. 相联存储器(CAM、Content Addressed Memory)：可以按照内容检索到存储位置进行读写的存储器，例如快表。

按照可更改性分类：
1. 读写存储器
2. 只读存储器

按照信息的可保存性分类：
- 按照断电后信息是否可保存分类：
	1. 易失性存储器：断电后信息丢失
	2. 非易失性存储器：断电后信息不丢失
- 按照信息读出后，原存储信息是否丢失分类：
	1. 破坏性读出存储器：读取后原信息被破坏，例如DRAM
	2. 非破坏性读出存储器：例如SRAM、磁盘、光盘等

## 3.2 主存储器

### 3.2.1 主存储器的基本构成

主存储器的基本构成如下图所示：
	![[Pasted image 20250306142951.png]]
	![[Pasted image 20250305160157.png]]
其可以简化为下图的结构：
	![[Pasted image 20250305160216.png]]
其中：
- MAR为内存地址寄存器(MAR、MDR都曾集成在RAM芯片中，但现代计算机中是集成在CPU中)
- MDR为内存数据寄存器
- 存储器负责存储二进制数据

### 3.2.2 DRAM和SRAM芯片

#### 3.2.2.1 DRAM芯片

DRAM为动态随机存储器，通常使用栅极电容存储信息，其特性有：
- 功耗较SRAM低
- 一个基本存储单元只需要一个晶体管，密度比SRAM高，速度比SRAM慢
- 读出数据时会消耗电容中的电荷，读出后应有重写操作，也称"再生"
	- <font color="#c00000">因此写入速度通常比读取慢</font>(例如Cache)
- 需要定期刷新以保持数据(电荷会流失)，通常2ms就要刷新一次
- 通常用于制作主存(运行内存)

DRAM和SRAM的存储单元差异可见下图：
	![[Pasted image 20250306161121.png]]
- 注：左为DRAM，右为SRAM

此外，由于DRAM内存较大，因此其译码器在设计时也不能像左侧那样只使用一个译码器去寻找 $2^n$ 个地址(此方案需要在译码器和存储单元之间连接 $2^n$ 个选通线)，所以通常设计成右侧的二维排列形式，将地址拆分为行地址和列地址(当然，现在已经有了三维的排列形式)。
	![[Pasted image 20250306162457.png]]

DRAM地址线复用技术：同一根线先后传输行地址和列地址，以达到行列地址线的复用。

##### 3.2.2.1.1 DRAM的刷新

DRAM的刷新：
1. 通常以行为单位，每次刷新一行。
2. 刷新时先读出数据，随后再次写入。
3. 刷新会占用一个读写周期。
因此在刷新时，有如下的刷新策略：
1. \[分散刷新\]：每次读写完都刷新一行：
	- 会导致读写的存取周期翻倍
2. \[集中刷新\]：2ms内集中刷新一次：
	- 这种策略在刷新时，CPU无法访问RAM，称为访存"死区"
3. \[异步刷新\]：依旧保持2ms刷新一次，但是一次只刷新一行，并把刷新操作分散到周期内：
	- 这种策略依旧会有死区，且死区总时长与上一方案相同，但是更容易把刷新操作分散到CPU不需要访问内存的时间内(例如CPU译码阶段)。

#### 3.2.2.2 SRAM芯片

SRAM为静态随机存储器，通常使用双稳态触发器存储信息，其特性有：
- 功耗比DRAM高
- 一个基本存储单元需要六个晶体管，密度地，价格高，速度更快
- 其有外置供电，读出数据不会破坏电平状态
- 通常用于制作Cache

DRAM和SRAM对比如下：

| <center>类型特点</center> |  SRAM  | DRAM |
| --------------------- | :----: | :--: |
| 信息存储单元                | 双稳态触发器 |  电容  |
| 读出是否破坏数据              |   否    |  是   |
| 读出后是否需要重写             |   否    |  是   |
| 访问速度                  |   快    |  慢   |
| 集成度                   |   低    |  高   |
| 功耗                    |   高    |  低   |
| 制造成本                  |   高    |  低   |
| 断电后数据是否丢失             |   是    |  是   |
| 是否需要刷新                |   否    |  是   |
| 常用场景                  | Cache  | 运行内存 |

#### 3.2.2.3 RAM的访问周期

![[Pasted image 20250305160157.png]]
以上图为例，一般来说，RAM的访问有如下几个环节：
1. CPU(直接或通过内存总线)把欲访问的地址放入内存地址寄存器(MAR)
2. 使用读写控制信号触发内存访问操作
3. RAM在时序控制逻辑的控制下：
	1. 使用地址译码器寻找记忆单元中MAR中地址对应的数据(行激活、列选择等)
	2. 将MAR中地址对应的数据存入内存数据寄存器(MDR)
4. 随后数据(直接或通过内存总线)传回CPU(的Cache中)
上述过程中，RAM的速度远慢于CPU的速度，且具体流程和时间消耗可见章节[[第三章 存储系统#^g0o5cw|DRAM的时序]]。
而为了解决RAM速度远低于CPU速度的问题，可见后续章节[[第三章 存储系统#^stctgo|RAM的并行访问与内存一致性]]技术。

##### 3.2.2.3.1 \[了解\]DRAM的时序 ^g0o5cw

CPU访问DRAM的流程为：
1. 确定内存通道，以及单个内存条上的DIMM。
2. Bank及行列选择：选择内存颗粒中的某个Bank，并指定目标的行列地址。
3. 行激活：
	1. 内存控制器向Bank发送RAS(Row Address Strobe)信号，传入行地址。
	2. 将Bank中的整行数据复制到行缓冲器(因为DRAM读取数据会破坏电荷)。
	3. 行激活完成后，颗粒会<font color="#c00000">自动</font>将行缓冲器中的数据回写到原存储单元。
4. 列选通：
	1. 内存控制器向Bank发送CAS(Column Address Strobe)信号，传入列地址。
	2. 从行缓冲器中选定特定的列数据。
5. 数据传递：
	1. 数据通过内存总线回传CPU。
6. 预充电：
	1. 完成当前行操作后，内存控制器发送Precharge命令，关闭当前激活的行。
	2. 行缓冲器清空，Bank准备接受下一行激活请求。

则DRAM的<font color="#9bbb59">时序参数</font>(并非总耗时)主要有：
1. <font color="#9bbb59">行激活时间</font>(tRAS)：行激活后必须保持开启的最短时间(要等待其他操作完成)，$tRAS\geq tRCD+CL+tRP$，若
2. <font color="#9bbb59">行到列延迟</font>(tRCD)：行激活后，发送CAS信号前，必须等待的最小时间间隔(用于等待行缓冲器稳定)
3. <font color="#9bbb59">列地址选通延迟</font>(CL)：CAS信号发送后，数据通过内存总线开始回传的时间间隔。
4. <font color="#9bbb59">行预充电时间</font>(tRP)：关闭当前已打开的行后(即预充电完成后)，在激活新行之前，必须等待的时间。

则DRAM访问的时间线为：

```text
        tRCD          CL            tRP
    |-----------|-------------|------------|
    ↑           ↑             ↑            ↑  
发送RAS      发送CAS       数据返回     下次行激活  
(行激活)     (列选通)      (数据传递)     (新访问)
```

则DRAM访问的耗时为：
1. 普通连续读取或单次读取：$T=tRCD+CL+tRP$
	![[Pasted image 20250310141542.png]]
2. 含有快速页面模式(Fast Page Mode，FPM)的同一行中的多次连续读取：$T=\displaystyle \frac{tRCD}{n}+CL+tRP$
	![[Pasted image 20250310141458.png]]
	- 使用于486和早期Pentium时代，目前已经完全淘汰
3. EDO(Extended Data Out、1994年后)：
4. 同步DRAM(SDRAM、1996年后)：
5. RDDRAM(Rambus DRAM、1999年)：
6. 双倍速率同步RAM(DDR SDRAM、2000年后)：

#TODO

### 3.2.3 只读存储器

只读存储器、Read Only Memory，ROM。其通常有如下几种：
1. MROM：掩膜式只读存储器，厂家生产后所有人都无法重写。
2. PROM：可编程只读存储器，用户可以用专用的PROM写入器写入信息，<font color="#c00000">写一次后</font>数据就不可更改。
3. EPROM：可擦除可编程只读存储器，允许用户写入信息和用某种方式擦除，<font color="#c00000">可多次重写</font>。
	1. UVEPROM：使用紫外线擦除，擦除时只能全部擦除。
	2. EEPROM：用电擦除，擦除时可选字或区域进行擦除。也可以缩写为E2PROM。
4. Flash：在EEPROM基础上发展而来，可进行多次快速擦除重写。写入前要擦除，写入速度比读取慢。每个存储元只需要一个MOS管+一个浮栅。

### 3.2.4 RAM的并行访问与内存一致性 ^stctgo

#### 3.2.4.1 双端口RAM

上述章节所描述的RAM模型只有一个数据总线和一个地址总线，当有多个硬件(如多核CPU、DMA等)需要同时访问时，则会遇到严重的性能问题。

那么此时可以引入双端口RAM，双端口RAM有两个地址总线和两个数据总线，支持两个设备的并行访问：
	![[Pasted image 20250307164714.png]]
其访问规则为：

| <center>行为</center> | <center>规则</center>                             |
| ------------------- | ----------------------------------------------- |
| 两个设备同时读取不同的地址       | 允许                                              |
| 两个设备同时读取相同的地址       | 允许                                              |
| 两个设备同时写入不同的地址       | 允许                                              |
| 两个设备同时写入相同的地址       | <font color="#c00000">不允许，RAM向设备发送Busy信号</font> |
| 两个设备分别读写相同的地址       | <font color="#c00000">不允许，RAM向设备发送Busy信号</font> |

#### 3.2.4.2 多体并行存储器(交叉编址)

在章节[[第三章 存储系统#^g0o5cw|DRAM的时序]]中讲到，在CPU完成一次对RAM的某个Bank访问之后，需要一定时间(tRP)的恢复才能访问该Bank的新行。但是在该等待时间内可以访问其他的Bank，因此需要将多个Bank之间进行交叉编制，明显地，交叉编址主要有如下两种：
1. 高位交叉编址：
	- ![[Pasted image 20250307171658.png]]
2. 地位交叉编址：
	- ![[Pasted image 20250307171710.png]]
类似于横向编址和纵向编址。由于局部性原则，内存访问通常具有局部性。为了最大化RAM利用率，减少平均存取周期，一般都选用低位交叉编址：
- 通常多体并行存取的体数量要大于"存取周期/存取时间"的值。
- ![[Pasted image 20250310145259.png]]

#### 3.2.4.3 单体多字存储器

将多个存储单元按高低位横向拼接，例如将4个1Byte存储体拼成4Byte存储体：
	![[Pasted image 20250310150039.png]]
- 可以用于将若干个窄字宽的存储器拼接到CPU的内存总线的位宽，可见章节[[第三章 存储系统#^0z0dt3|主存容量的拓展]]。

#### 3.2.4.4 MESI

在CPU进行运算或操作时，<font color="#c00000">其数据一定存放于寄存器中</font>。因此在具有多级缓存的CPU架构下，CPU操作数据时，其流程为(假设访问区域合法)：
1. 查询L1缓存中有无目标数据，如有则读入寄存器，如无则查询L2缓存
2. 查询L2缓存中有无目标数据，如有则读入L1缓存，如无则查询L3缓存
3. 查询L3缓存中有无目标数据，如有则读入L2缓存，如无则查询RAM
4. 查询目标地址是否在RAM中，如有则读入缓存，如无则去Swap中查找





#TODO





## 3.3 主存储器与CPU之间的连接

### 3.3.1 连接原理

现代计算机中：
- MAR、MDR集成于CPU中，CPU和内存颗粒通过数据总线、地址总线、控制线进行连接：
	- 示意图为：![[Obsidian_r0hUfblY63.png]]
	- 片选线：$CE$ (高电平有效)或 $\overline{CE}$ (低电平有效)或 $CS$ / $\overline{CS}$
	- 读写控制：
		- 读写合并控制：$WE$ / $\overline{WE}$ / $WR$ / $\overline{WR}$
		- 读写独立控制：
			- 读控制：$OE$ / $\overline{OE}$
			- 写控制：$WE$ / $\overline{WE}$
- 单颗DRAM芯片的地址总线通常为14-18位，数据总线宽度常见为：
	- 4位：用于高密度存储应用，例如服务器内存
	- 8位：用于消费级应用，例如PC
	- 16位：常用于低功耗移动端设备
- CPU和主存储器的连接通常为：
	![[Pasted image 20250305160157.png]]
	- 其中：
		- 数据总线被命名为：$D_x$，例如 $D_0$ 、$D_1$ ...
		- 地址总线被命名为：$A_x$

### 3.3.2 主存容量的拓展 ^0z0dt3

#### 3.3.2.1 位拓展法

当DRAM存储芯片的<span style="background:#fff88f"><font color="#c00000">数据位</font></span>宽度小于CPU的数据总线宽度时，可以将若干个DRAM存储芯片在位宽度上拓展到对应的总线宽度即可：
	![[Pasted image 20250310154223.png]]
- CS信号也同步控制即可。

#### 3.3.2.2 字拓展法

当DRAM存储芯片的地址位宽度小于CPU的地址总线宽度，并且需要拓展到足够的内存时，可以将地址总线用译码器进行管理即可：
	![[Pasted image 20250310155642.png]]

#### 3.3.2.3 字位同时拓展法

排列组合即可：
	![[Pasted image 20250310160127.png]]

## 3.4 外部存储器






